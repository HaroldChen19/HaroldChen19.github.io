---
layout: default
---

<body>	
	
<div class="content heading anchor" id="home">
		<table style="margin-top: -4mm;">
		</table>
        <div style="margin-top: 0mm;" class="img">
			<img class="header-img" src="images/homepage3.jpg" alt="Photo" align="left" height="240" >
		</div>
        <div style="margin-top: 7mm;" class="header-text">
            <h2>Harold Haodong Chen</h2>
            <p>
				Ph.D. Student <br> 
				The Hong Kong University of Science and Technology <br>
				Email: haroldchen328 [at] gmail.com <br>
            </p>
		<div id="contact">	
			<a href="https://scholar.google.com/citations?hl=en&user=BGUdPBAAAAAJ" class="icon">
          			<img src="images/ico/scholar.png"  alt="View Harold Chen's profile on Google Scholar", height="30px" style="margin-bottom:-3px">
          		</a>
          		<a href="https://github.com/HaroldChen19" class="icon">
          			<img src="images/ico/github_s.jpg"  alt="View Harold Chen's codes on Github", height="30px" style="margin-bottom:-3px">
          		</a>
          		<a href="https://x.com/HaroldChen68578" class="icon">
					<img src="images/ico/x.png"  alt="View Harold Chen's profile on X", height="30px" style="margin-bottom:-3px">
				</a>
				<a href="javascript:void(0);" class="icon" onmouseover="showWeChatQRCode()" onmouseout="hideWeChatQRCode()">
					<img src="images/ico/wechat.jpeg"  alt="View Harold Chen's profile on X", height="30px" style="margin-bottom:-3px">
				</a>
        </div>
		<div id="wechat-qr-code" style="display: none; position: absolute; z-index: 100;">
			<img src="images/wechat2.png" alt="WeChat QR Code" style="width: 200px; height: 200px;" />
		</div>
		<script>
            function showWeChatQRCode() {
              var qrCode = document.getElementById('wechat-qr-code');
              qrCode.style.display = 'block';
            }
            
            function hideWeChatQRCode() {
              var qrCode = document.getElementById('wechat-qr-code');
              qrCode.style.display = 'none';
            }
		</script>
	  </div>
</div>	   

<table hegiht="50"><td hegiht="50"></td></table>
<table hegiht="50"><td hegiht="50"></td></table>
<table hegiht="50"><td hegiht="50"></td></table>

	   
<div class="content anchor" id="bio">     
	<h3 class="content-section">Biography</h3>


		<!-- <p style="text-align: justify">	I'm a final-year undergraduate student at Northwestern Polytechnical University (NPU) and an incoming PhD student (2025 Fall) at The Hong Kong University of Science and Technology (HKUST). I'm fortunate to work closely with Prof. <a href="https://sites.google.com/site/sernam" target="_blank">Ser-Nam Lim</a>, Prof. <a href="https://leehomyc.github.io/" target="_blank">Harry Yang</a>, Prof. <a href="https://cqf.io/" target="_blank">Qifeng Chen</a> and Prof. <a href="https://scholar.google.com/citations?user=amxDSLoAAAAJ&hl=en" target="_blank">Dian Shao</a>.
			<br> -->
		<!-- <p style="text-align: justify">	I'm a PhD student at The Hong Kong University of Science and Technology (HKUST), supervised by Prof. <a href="https://leehomyc.github.io/" target="_blank">Harry Yang</a> and Prof. <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>. I obtained my B.S. degree at Northwestern Polytechnical University (NPU) in 2025, where I worked closely with Prof. <a href="https://scholar.google.com/citations?user=amxDSLoAAAAJ&hl=en" target="_blank">Dian Shao</a>. I'm also fortunate to work closely with Prof. <a href="https://www.yingcong.me/" target="_blank">Ying-Cong Chen</a> and Prof. <a href="https://sites.google.com/site/sernam" target="_blank">Ser-Nam Lim</a>.
			<br> -->
		<p style="text-align: justify">	I'm a PhD student at The Hong Kong University of Science and Technology (HKUST), supervised by Prof. <a href="https://www.yingcong.me/" target="_blank">Ying-Cong Chen</a> and Prof. <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>. I obtained my B.E. degree at Northwestern Polytechnical University (NPU) with Outstanding Graduate Award in 2025, where I worked closely with Prof. <a href="https://scholar.google.com/citations?user=amxDSLoAAAAJ&hl=en" target="_blank">Dian Shao</a>. I'm also fortunate to work closely with Prof. <a href="https://leehomyc.github.io/" target="_blank">Harry Yang</a> and Prof. <a href="https://sites.google.com/site/sernam" target="_blank">Ser-Nam Lim</a>.
			<br>

		<!-- <p style="text-align: justify"> Previously, I was advised by Prof. <a href="https://scholar.google.com/citations?user=amxDSLoAAAAJ&hl=en" target="_blank">Dian Shao</a> from both NPU and Shanghai AI Laboratory, which contributed to my development in this field. I also worked with Prof. <a href="https://scholar.google.com/citations?user=8P7q1wQAAAAJ&hl=zh-CN" target="_blank">Mulin Chen</a> and Prof. <a href="https://scholar.google.com/citations?user=ahUibskAAAAJ&hl=zh-CN" target="_blank">Xuelong Li</a> from TeleAI, China Telecom, as well as Prof. <a href="https://scholar.google.com/citations?user=n9cODgcAAAAJ" target="_blank">Yuxuan Liang</a> from HKUST(GZ). -->
			
		<p style="text-align: justify"> I am always open to all forms of research collaboration. Feel free to contact me if you are interested in working with me! My research interests include <strong>Video Generation &amp; Understanding</strong>, <strong>Agentic System</strong>, and <strong>Embodied AI</strong>.
		</p>
		<!-- <ul>
			<li><strong>Video Generation:</strong> RFT, test-time, efficient generation</li>
			<li><strong>Large Video Model:</strong> RFT, DPO, unified understanding &amp; generation </li>
			<li><strong>Embodied AI:</strong> RFT, VLA</li>
		</ul> -->
</div>   
	
<div class="content anchor" id="news">  
	<h3 class="content-section-list">News</h3>
	<p>
	<li>
		[11/2025] One paper is accepted to AAAI'26!
	<li>
		[09/2025] One paper is accepted to NeurIPS'25!
	<li>
		[07/2025] One paper is accepted to MM'25!
	<li>
		[05/2025] One paper is accepted to ICML'25!
	<li>
		[02/2025] One paper is accepted to CVPR'25!
	<li>
		[02/2025] Served as a reviewer for ICCV'25.
	<li>
		[02/2025] Served as a reviewer for Pattern Recognition.
	<!-- <li>
		[01/2025] Served as a reviewer for ACM TOMM. -->
	<li>
		[12/2024] Served as a reviewer for ICML'25.
	<li>
		[12/2024] One paper is accepted to AAAI'25!
	
	<details><summary>More</summary>
	<li>
		[11/2024] Served as a reviewer for CVPR'25.
	<!-- <li>
		[10/2024] Served as a reviewer for AISTATS'25. -->
	<li>
		[08/2024] Served as a reviewer for ICLR'25.
	<li>
		[07/2024] Two paper are accepted to MM'24!
	<li>
		[05/2024] Served as a reviewer for NeurIPS'24.
	<li>
		[02/2024] Served as a reviewer for ECCV'24.
	<li>
		[01/2024] Served as a reviewer for MM'24.
	<li>
		[01/2024] One paper is accepted to WWW'24 as <span style="font-weight: bold;"><font color="#f00">Oral Presentation</font></span>!
	</li>
	</details>
	</p>
</div>   

<div class="content anchor" id="publication">     
	<h3  class="content-section">
	Experience
	</h3>


	<table bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody>
			<tr valign="baseline">
				<td width="160">
					<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class="">
						<img src="./images/institute/hkust_2.png" width="160" border="0">
					</p>
				</td>
				<td valign="middle">
					<p>
						<span style="font-weight: bold;">Visiting Student </span>| HKUST<br>
						Time: 11/2024 - 6/2025. Advisor: Prof. <a href="https://leehomyc.github.io/" target="_blank">Harry Yang</a>
					</p>
				</td>
			</tr>
		</tbody>
	</table>

	<table bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody>
			<tr valign="baseline">
				<td width="160">
					<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class="">
						<img src="./images/institute/everlyn_1.png" width="160" border="0">
					</p>
				</td>
				<td valign="middle">
					<p>
						<span style="font-weight: bold;">Research Intern </span>| Everlyn AI<br>
						Time: 8/2024 - 5/2025. Mentor: Prof. <a href="https://sites.google.com/site/sernam" target="_blank">Ser-Nam Lim</a>
					</p>
				</td>
			</tr>
		</tbody>
	</table>
	
	<table bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody>
			<tr valign="baseline">
				<td width="160">
					<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class="">
						<img src="./images/institute/hkgai.png" width="160" border="0">
					</p>
				</td>
				<td valign="middle">
					<p>
						<span style="font-weight: bold;">Research Intern </span>| HKGAI<br>
						Time: 5/2024 - 8/2024. Mentor: Prof. <a href="https://whluo.github.io/" target="_blank">Wenhan Luo</a>
					</p>
				</td>
			</tr>
		</tbody>
	</table>
	
	

</div>


<div class="content anchor" id="publication">     
	<h3  class="content-section">
	Selected Preprints
	</h3>

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/tivibench2.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;">TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models </span><br>
			<span style="font-weight: bold;"><u>Harold Haodong Chen*</u></span>, Disen Lan*, Wen-Jie Shu*, Qingyang Liu, Sirui Chen, Wenkai Cheng, Kanghao Chen, Hongfei Zhang, Zixin Zhang, Rongjin Guo, Yu Cheng<sup>&dagger;</sup>, Ying-Cong Chen<sup>&dagger;</sup>
			<br>
			<i>Benchmark Paper, 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2511.13704">[arXiv]</a></span>
			<span class="tag"><a href="https://haroldchen19.github.io/TiViBench-Page/">[Webpage]</a></span>
			<span class="tag"><a href="https://github.com/EnVision-Research/TiViBench">[Code & Data]</a></span>
		</td>
	</tbody>
	</table>

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/scalingar.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> Go with Your Gut: Scaling Confidence for Autoregressive Image Generation </span><br>
			<span style="font-weight: bold;"><u>Harold Haodong Chen*</u></span>, Xianfeng Wu*, Wen-Jie Shu, Rongjin Guo, Disen Lan, Harry Yang, Ying-Cong Chen<sup>&dagger;</sup>
			<br>
			<i>Preprint, 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2509.26376">[arXiv]</a></span>
			<span class="tag"><a href="https://github.com/EnVision-Research/ScalingAR">[Code]</a></span>
		</td>
	</tbody>
	</table>

	<!-- <table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/fluxflow_new.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> Temporal Regularization Makes Your Video Generator Stronger </span><br>
			<span style="font-weight: bold;"><u>Harold Haodong Chen</u></span>, Haojian Huang, Xianfeng Wu, Yexin Liu, Yajing Bai, Wen-Jie Shu, Harry Yang<sup>&dagger;</sup>, Ser-Nam Lim<sup>&dagger;</sup>
			<br>
			<i>Technical Report, 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2503.15417">[arXiv]</a></span>
			<span class="tag"><a href="https://haroldchen19.github.io/FluxFlow/">[Webpage]</a></span>
		</td>
	</tbody>
	</table> -->

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/lightgen_new.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> LightGen: Efficient Image Generation through Knowledge Distillation and Direct Preference Optimization </span><br>
			Xianfeng Wu*, Yajing Bai*, Haoze Zheng*, <span style="font-weight: bold;"><u>Harold Haodong Chen</u>* <font color="lightcoral">(co-first)</font></span>, Yexin Liu*, Zihao Wang, Xuran Ma, Wen-Jie Shu, Harry Yang<sup>&dagger;</sup>, Ser-Nam Lim<sup>&dagger;</sup><br>
			<i>Technical Report, 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2503.08619">[arXiv]</a></span>
			<span class="tag"><a href="https://github.com/XianfengWu01/LightGen">[Code]</a></span>
		</td>
	</tbody>
	</table>

	<!-- <table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/ues.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> Beyond Generation: Unlocking Universal Editing via Self-Supervised Fine-Tuning </span><br>
			<span style="font-weight: bold;"><u>Harold Haodong Chen</u></span>, Harry Yang<sup>&dagger;</sup>, Ser-Nam Lim<sup>&dagger;</sup>
			<br>
			arXiv, 2024 <br>
			<span class="tag"><a href="https://arxiv.org/abs/2412.02114">[arXiv]</a></span>
			<span class="tag"><a href="https://haroldchen19.github.io/UES-Page/">[Webpage]</a></span>
			<span class="tag"><a href="https://github.com/HaroldChen19/UES">[Code]</a></span>
			<span class="tag"><a href="https://huggingface.co/datasets/Harold328/OmniBench-99">[Benchmark]</a></span>
		</td>
	</tbody>
	</table> -->

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/gsvton_new.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> GaussianVTON: 3D Human Virtual Try-ON via Multi-Stage Gaussian Splatting Editing with Image Prompting
			</span><br>
			<span style="font-weight: bold;"><u>Haodong Chen</u></span>, Yongle Huang, Haojian Huang, Xiangsheng Ge, Dian Shao<sup>&dagger;</sup>
			<br>
			<i>Technical Report, 2024</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2405.0747">[arXiv]</a></span>
			<span class="tag"><a href="https://haroldchen19.github.io/gsvton/">[Webpage]</a></span>
			<span class="tag"><a href="https://github.com/HaroldChen19/GaussianVTON">[Code]</a></span>
		</td>
	</tbody>
	</table>
	

	
</div>

	
<div class="content anchor" id="publication">     
	<h3  class="content-section">
	Selected Publications
	</h3>

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/physhpo_new1.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation</span><br>
			<span style="font-weight: bold;"><u>Harold Haodong Chen</u></span>, Haojian Huang, Qifeng Chen, Harry Yang<sup>&dagger;</sup>, Ser-Nam Lim<sup>&dagger;</sup>
			<br>
			<i>Annual Conference on Neural Information Processing Systems
			(<span style="font-weight: bold;">NeurIPS</span>), 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2508.10858">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2508.10858">[arXiv]</a></span>
			<span class="tag"><a href="https://haroldchen19.github.io/PhysHPO-Page/">[Webpage]</a></span>
		</td>
	</tbody>
	</table>

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/finequest.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via Agent-of-Thoughts Reasoning</span><br>
			<span style="font-weight: bold;"><u>Haodong Chen</u></span>, Haojian Huang, Xinxiang Yin, Dian Shao<sup>&dagger;</sup>
			<br>
			<i>ACM International Conference on Multimedia
			(<span style="font-weight: bold;">MM</span>), 2025 <font color="#f00">(Oral Presentation)</font></span></i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2509.11796">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2509.11796">[arXiv]</a></span>
		</td>
	</tbody>
	</table>


	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/vista.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference Optimization for Large Video Models </span><br>
			Haojian Huang*, <span style="font-weight: bold;"><u>Haodong Chen</u>* <font color="lightcoral">(co-first)</font></span>, Shengqiong Wu, Meng Luo, Jinlan Fu, Xinya Du, Hanwang Zhang, Hao Fei<sup>&dagger;</sup>
			<br>
			<i>International Conference on Machine Learning
			(<span style="font-weight: bold;">ICML</span>), 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2504.13122">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2504.13122">[arXiv]</a></span>
			<span class="tag"><a href="https://github.com/HaroldChen19/VistaDPO">[Code]</a></span>
			<span class="tag"><a href="https://huggingface.co/datasets/Harold328/VistaDPO-7K">[Dataset]</a></span>
		</td>
	</tbody>
	</table>

	<!-- <table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/finephys.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;">FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance</span><br>
			Dian Shao<sup>&dagger;</sup>, Mingfei Shi, Shengda Xu, <span style="font-weight: bold;"><u>Haodong Chen</u></span>, Yongle Huang, Binglu Wang
			<br>
			<i>IEEE/CVF Computer Vision and Pattern Recognition
			(<span style="font-weight: bold;">CVPR</span>), 2025</i><br>
			<span class="tag"><a href="https://arxiv.org/abs/2505.13437">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2505.13437">[arXiv]</a></span>
			<span class="tag"><a href="https://mingfeishims.github.io/projects-FinePhys/">[Webpage]</a></span>
			<span class="tag"><a href="https://github.com/SmartDianLab/FinePhys">[Code]</a></span>
		</td>
	</tbody>
	</table> -->

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/sefar.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> SeFAR: Semi-supervised Fine-grained Action Recognition with Temporal Perturbation and Learning Stabilization
			</span><br>
			Yongle Huang*, <span style="font-weight: bold;"><u>Haodong Chen</u>* <font color="lightcoral">(co-first)</font></span>, Zhenbang Xu, Zihan Jia, Haozhou Sun, Dian Shao<sup>&dagger;</sup>
			<br>
			<i>AAAI Conference on Artificial Intelligence
			(<span style="font-weight: bold;">AAAI</span>), 2025</i><br>
			<span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32400">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2501.01245">[arXiv]</a></span>
			<span class="tag"><a href="https://github.com/KyleHuang9/SeFAR">[Code]</a></span>
			<span class="tag"><a href="https://github.com/KyleHuang9/SeFAR">[Dataset]</a></span>
		</td>
	</tbody>
	</table>

	<table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/finecliper.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs
			</span><br>
			<span style="font-weight: bold;"><u>Haodong Chen</u></span>, Haojian Huang, Junhao Dong, Mingzhe Zheng, Dian Shao<sup>&dagger;</sup> <br>
			<i>ACM International Conference on Multimedia
			(<span style="font-weight: bold;">MM</span>), 2024</i><br>
			<span class="tag"><a href="https://dl.acm.org/doi/10.1145/3664647.3680827">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2407.02157">[arXiv]</a></span>
			<span class="tag"><a href="https://haroldchen19.github.io/FineCLIPER-Page/">[Webpage]</a></span>
		</td>
	</tbody>
	</table>
	
	<!-- <table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/CREST.png" width="160"  border="0"></p>
		</td>
	<td  valign="middle">
		<p><span style="font-weight: bold;"> CREST: Cross-modal Resonance through Evidential Deep Learning for Enhanced Zero-Shot Learning </span><br>
			 Haojian Huang, Xiaozhen Qiao, Zhuo Chen, <span style="font-weight: bold;"><u>Haodong Chen</u></span>, Bingyu Li, Zhe Sun, Mulin Chen<sup>&dagger;</sup>, Xuelong Li<sup>&dagger;</sup>
			<br>
			<i>ACM International Conference on Multimedia
			(<span style="font-weight: bold;">MM</span>), 2024</i><br>
			<span class="tag"><a href="https://dl.acm.org/doi/10.1145/3664647.3681629">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2404.09640">[arXiv]</a></span>
			<span class="tag"><a href="https://github.com/JethroJames/CREST">[Code]</a></span>
		</td>
	</tbody>
	</table> -->

	<!-- <table  bordercolor="white" bordercolordark="white" bordercolorlight="white" cellpadding="0" cellspacing="0" height="45" bgcolor="white">
		<tbody><tr valign="baseline">
		<td width="160">
			<p align="center" style="margin-top:2.5mm; margin-right:1mm; margin-bottom:0; margin-left:0;" class=""><img src="./images/papers/urbanclip.png" width="160"  border="0"></p>
		</td>
		<td  valign="middle">
			<p><span style="font-weight: bold;"> UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web
			</span><br>
			Yibo Yan, Haomin Wen, Siru Zhong, Wei Chen, <span style="font-weight: bold;"><u>Haodong Chen</u></span>, Qingsong Wen, Roger Zimmermann, Yuxuan Liang<sup>&dagger;</sup>
			<br>
			<i>ACM International World Wide Web Conference
			(<span style="font-weight: bold;">WWW</span>), 2024 <span style="font-weight: bold;"><font color="#f00">(Oral Presentation)</font></span></i><br>
			<span class="tag"><a href="https://dl.acm.org/doi/10.1145/3589334.3645378">[Paper]</a></span>
			<span class="tag"><a href="https://arxiv.org/abs/2310.18340">[arXiv]</a></span>
			<span class="tag"><a href="https://www.youtube.com/watch?v=FdIZ7oJfmkg">[Video]</a></span>
			<span class="tag"><a href="https://github.com/StupidBuluchacha/UrbanCLIP">[Code]</a></span>
		</td>
	</tbody>
	</table> -->

	
</div>





<div class="content anchor" >    
	<h3 class="content-section-list">Awards and Honors</h3>  
		<p>
			<table style="border-spacing:2px" width="100%">
			<tbody>
			<tr><td><li>
				Postgraduate Scholarship, HKUST(GZ)  </td> <td align="right"> 2025 </td></tr>
			<tr><td><li>
				Outstanding Graduate, NPU  </td> <td align="right"> 2025 </td></tr>
			<tr><td><li>
				Postgraduate Scholarship, HKUST  </td> <td align="right"> 2025 </td></tr>
			<!-- <tr><td><li>
				Innovation and Entrepreneurship Advanced Individual Honor, NPU</td> <td align="right"> 2024 </td></tr> -->
			<tr><td><li>
				Outstanding University Student, NPU  </td> <td align="right"> 2023-2024 </td></tr>
			<tr><td><li>
				University Scholarship, NPU  </td> <td align="right"> 2023-2024 </td></tr>
			<tr><td><li>
				University Student Innovation Fund, Ministry of Education of P.R. China </td> <td align="right"> 2023 </td></tr>
			<!-- <tr><td><li>
				Academic Advancement Individual Honor, NPU </td> <td align="right"> 2023 </td></tr> -->
			<!-- <tr><td><li>
				School Scholarship, NPU  </td> <td align="right"> 2023 </td></tr> -->
			</li>
			</tbody>
			</table>

			<!-- <details><summary>More</summary>
			<table style="border-spacing:2px" width="100%">
			<tbody>
			<tr><td><li>Nanjing University Outstanding Student Leader Award</td> <td align="right"> 2015</td></tr>
			</li>
			</tbody>
			</table>
			</details> -->
	</p>
</div>    

	
<!-- <div class="content anchor" id="talks">
	<h3 class="content-section-list">Talks</h3>

	<p>
		<table style="border-spacing:2px" width="100%">
		<body>

		<tr><td><li>Bridging the Representation Gap of Humans and Computers for Video Production</td></tr>
		<tr><td>
			<ul><ul>
				<li>China Golden Rooster Film Festival, 11/2024</li>
				<li>World Artificial Intelligence Conference (WAIC), 07/2024</li>
				<li>Shanghai Television Magnolia Festival, 06/2024</li>
				<li>University of Hong Kong (HKU), 05/2024</li>
				<li>Hong Kong University of Science and Technology (HKUST), 05/2024</li>
				<li>Stanford University, 04/2024</li>
				<li><a style="color:#333" href="https://datascience.hku.hk/hk-sh-ai-forum-2024/">Hong Kong Shanghai AI Forum</a>, 04/2024</li>
			</ul></ul>
		</td></tr>
		

		</tbody>
		</table>
	</p> -->

<!-- </div>    -->


<div class="content anchor" id="service">
	<h3 class="content-section-list">Services</h3>
	<p>
		<li>Conference Reviewer,
			<!-- <br>&emsp;&emsp;2024, European Conference on Computer Vision (ECCV) 
			<br>&emsp;&emsp;2024, ACM International Conference on Multimedia (MM)
			<br>&emsp;&emsp;2024-2025, Neural Information Processing Systems (NeurIPS)
			<br>&emsp;&emsp;2025, Computer Vision and Pattern Recognition (CVPR)
			<br>&emsp;&emsp;2025, International Conference on Machine Learning (ICML)
			<br>&emsp;&emsp;2025, International Conference on Computer Vision (ICCV)
			<br>&emsp;&emsp;2025-2026, International Conference on Learning Representations (ICLR)
			<br>&emsp;&emsp;2025-2026, Artificial Intelligence and Statistics (AISTATS)
			<br>&emsp;&emsp;2026, AAAI Conference on Artificial Intelligence (AAAI) -->
			<br>&emsp;&emsp;European Conference on Computer Vision (ECCV), 2024
			<br>&emsp;&emsp;ACM International Conference on Multimedia (MM), 2024
			<br>&emsp;&emsp;Neural Information Processing Systems (NeurIPS), 2024-2025
			<br>&emsp;&emsp;International Conference on Machine Learning (ICML), 2025
			<br>&emsp;&emsp;International Conference on Computer Vision (ICCV), 2025
			<br>&emsp;&emsp;International Conference on Learning Representations (ICLR), 2025-2026
			<br>&emsp;&emsp;Computer Vision and Pattern Recognition (CVPR), 2025-2026
			<br>&emsp;&emsp;Artificial Intelligence and Statistics (AISTATS), 2025-2026
			<br>&emsp;&emsp;AAAI Conference on Artificial Intelligence (AAAI), 2026
		</li>
		<li>Journal Reviewer,
			<br>&emsp;&emsp;Pattern Recognition, ACM TOMM
		</li>
	</p>
</div>

	<div style="text-align:center; width:300px; height:300px; margin: 0 auto; overflow:hidden;">
		<script type='text/javascript' id='mapmyvisitors' 
				src='https://mapmyvisitors.com/map.js?cl=9d97b5&w=a&t=tt&d=K5mXqzOGNWeXE2Ezi93zbcP2GhxzuJjlVPOeC5nKM24&co=ffffff&cmo=9189eb&cmn=c77474&ct=2e2b2b'>
		</script>
	</div>

</body>
